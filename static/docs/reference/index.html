<!-- Generated by pkgdown: do not edit by hand -->
<!DOCTYPE html>
<html lang="en">
  <head>
  <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>Function reference â€¢ torch</title>


<!-- jquery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script>
<!-- Bootstrap -->
<link href="https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.4.0/united/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous" />


<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script>

<!-- bootstrap-toc -->
<link rel="stylesheet" href="../bootstrap-toc.css">
<script src="../bootstrap-toc.js"></script>

<!-- Font Awesome icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous" />

<!-- clipboard.js -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script>

<!-- headroom.js -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script>

<!-- pkgdown -->
<link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script>



  <link href="../extra.css" rel="stylesheet">
  

<meta property="og:title" content="Function reference" />




<!-- mathjax -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script>

<!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->


<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-178883486-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-178883486-1');
</script>


  </head>

  <body data-spy="scroll" data-target="#toc">
    <div class="container template-reference-index">
      <header>
      <div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">torch</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">0.1.1</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="../index.html">
    <span class="fas fa fas fa-home fa-lg"></span>
     
  </a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Getting started
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">Beginers guide</li>
    <li>
      <a href="../articles/getting-started/warmup.html">Warm-up</a>
    </li>
    <li>
      <a href="../articles/getting-started/tensors.html">Tensors</a>
    </li>
    <li>
      <a href="../articles/getting-started/tensors-and-autograd.html">Tensors and autograd</a>
    </li>
    <li>
      <a href="../articles/getting-started/new-autograd-functions.html">Defining new autograd functions</a>
    </li>
    <li>
      <a href="../articles/getting-started/nn.html">nn: neural networks with torch</a>
    </li>
    <li>
      <a href="../articles/getting-started/optim.html">optim: optimizers in torch</a>
    </li>
    <li>
      <a href="../articles/getting-started/custom-nn.html">Custom nn modules</a>
    </li>
    <li>
      <a href="../articles/getting-started/control-flow-and-weight-sharing.html">Control flow &amp; Weight sharing</a>
    </li>
    <li class="dropdown-header">Torch Mechanics</li>
    <li>
      <a href="../articles/getting-started/what-is-torch.html">What's torch?</a>
    </li>
    <li>
      <a href="../articles/getting-started/autograd.html">Autograd: automatic differentiation</a>
    </li>
    <li>
      <a href="../articles/getting-started/neural-networks.html">Neural networks</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">Tensors</li>
    <li>
      <a href="../articles/tensor-creation.html">Creating tensors</a>
    </li>
    <li>
      <a href="../articles/indexing.html">Indexing</a>
    </li>
    <li>
      <a href="../articles/tensor/index.html">Tensor class</a>
    </li>
    <li>
      <a href="../articles/serialization.html">Serialization</a>
    </li>
    <li class="dropdown-header">Datasets</li>
    <li>
      <a href="../articles/loading-data.html">Loading Data</a>
    </li>
    <li class="dropdown-header">Autograd</li>
    <li>
      <a href="../articles/using-autograd.html">Using autograd</a>
    </li>
    <li>
      <a href="../articles/extending-autograd.html">Extending autograd</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Examples
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="../articles/examples/basic-autograd.html">basic-autograd</a>
    </li>
    <li>
      <a href="../articles/examples/basic-nn-module.html">basic-nn-module</a>
    </li>
    <li>
      <a href="../articles/examples/dataset.html">dataset</a>
    </li>
  </ul>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li>
  <a href="../news/index.html">Changelog</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/mlverse/torch/">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
      
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

      

      </header>

<div class="row">
  <div class="contents col-md-9">
    <div class="page-header">
      <h1>Reference</h1>
    </div>

    <table class="ref-index">

    <colgroup>
      
      <col class="alias" />
      <col class="title" />
    </colgroup>

    <tbody>
      <tr>
        <th colspan="2">
          <h2 id="section-tensor-creation-utilities" class="hasAnchor"><a href="#section-tensor-creation-utilities" class="anchor"></a>Tensor creation utilities</h2>
          <p class="section-desc"></p>
        </th>
      </tr>
      
      
    </tbody><tbody>
      
      
      <tr>
        
        <td>
          <p><code><a href="torch_empty.html">torch_empty()</a></code> </p>
        </td>
        <td><p>Empty</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_arange.html">torch_arange()</a></code> </p>
        </td>
        <td><p>Arange</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_eye.html">torch_eye()</a></code> </p>
        </td>
        <td><p>Eye</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_full.html">torch_full()</a></code> </p>
        </td>
        <td><p>Full</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_linspace.html">torch_linspace()</a></code> </p>
        </td>
        <td><p>Linspace</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_logspace.html">torch_logspace()</a></code> </p>
        </td>
        <td><p>Logspace</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_ones.html">torch_ones()</a></code> </p>
        </td>
        <td><p>Ones</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_rand.html">torch_rand()</a></code> </p>
        </td>
        <td><p>Rand</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_randint.html">torch_randint()</a></code> </p>
        </td>
        <td><p>Randint</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_randn.html">torch_randn()</a></code> </p>
        </td>
        <td><p>Randn</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_randperm.html">torch_randperm()</a></code> </p>
        </td>
        <td><p>Randperm</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_zeros.html">torch_zeros()</a></code> </p>
        </td>
        <td><p>Zeros</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_empty_like.html">torch_empty_like()</a></code> </p>
        </td>
        <td><p>Empty_like</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_full_like.html">torch_full_like()</a></code> </p>
        </td>
        <td><p>Full_like</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_ones_like.html">torch_ones_like()</a></code> </p>
        </td>
        <td><p>Ones_like</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_rand_like.html">torch_rand_like()</a></code> </p>
        </td>
        <td><p>Rand_like</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_randint_like.html">torch_randint_like()</a></code> </p>
        </td>
        <td><p>Randint_like</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_randn_like.html">torch_randn_like()</a></code> </p>
        </td>
        <td><p>Randn_like</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_zeros_like.html">torch_zeros_like()</a></code> </p>
        </td>
        <td><p>Zeros_like</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="as_array.html">as_array()</a></code> </p>
        </td>
        <td><p>Converts to array</p></td>
      </tr>
    </tbody><tbody>
      <tr>
        <th colspan="2">
          <h2 id="section-tensor-attributes" class="hasAnchor"><a href="#section-tensor-attributes" class="anchor"></a>Tensor attributes</h2>
          <p class="section-desc"></p>
        </th>
      </tr>
      
      
    </tbody><tbody>
      
      
      <tr>
        
        <td>
          <p><code><a href="default_dtype.html">torch_set_default_dtype()</a></code> <code><a href="default_dtype.html">torch_get_default_dtype()</a></code> </p>
        </td>
        <td><p>Gets and sets the default floating point dtype.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="is_torch_device.html">is_torch_device()</a></code> </p>
        </td>
        <td><p>Checks if object is a device</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="is_torch_dtype.html">is_torch_dtype()</a></code> </p>
        </td>
        <td><p>Check if object is a torch data type</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_dtype.html">torch_float32()</a></code> <code><a href="torch_dtype.html">torch_float()</a></code> <code><a href="torch_dtype.html">torch_float64()</a></code> <code><a href="torch_dtype.html">torch_double()</a></code> <code><a href="torch_dtype.html">torch_float16()</a></code> <code><a href="torch_dtype.html">torch_half()</a></code> <code><a href="torch_dtype.html">torch_uint8()</a></code> <code><a href="torch_dtype.html">torch_int8()</a></code> <code><a href="torch_dtype.html">torch_int16()</a></code> <code><a href="torch_dtype.html">torch_short()</a></code> <code><a href="torch_dtype.html">torch_int32()</a></code> <code><a href="torch_dtype.html">torch_int()</a></code> <code><a href="torch_dtype.html">torch_int64()</a></code> <code><a href="torch_dtype.html">torch_long()</a></code> <code><a href="torch_dtype.html">torch_bool()</a></code> <code><a href="torch_dtype.html">torch_quint8()</a></code> <code><a href="torch_dtype.html">torch_qint8()</a></code> <code><a href="torch_dtype.html">torch_qint32()</a></code> </p>
        </td>
        <td><p>Torch data types</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_finfo.html">torch_finfo()</a></code> </p>
        </td>
        <td><p>Floating point type info</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_iinfo.html">torch_iinfo()</a></code> </p>
        </td>
        <td><p>Integer type info</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_qscheme.html">torch_per_channel_affine()</a></code> <code><a href="torch_qscheme.html">torch_per_tensor_affine()</a></code> <code><a href="torch_qscheme.html">torch_per_channel_symmetric()</a></code> <code><a href="torch_qscheme.html">torch_per_tensor_symmetric()</a></code> </p>
        </td>
        <td><p>Creates the corresponding Scheme object</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_reduction.html">torch_reduction_sum()</a></code> <code><a href="torch_reduction.html">torch_reduction_mean()</a></code> <code><a href="torch_reduction.html">torch_reduction_none()</a></code> </p>
        </td>
        <td><p>Creates the reduction objet</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="is_torch_layout.html">is_torch_layout()</a></code> </p>
        </td>
        <td><p>Check if an object is a torch layout.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="is_torch_memory_format.html">is_torch_memory_format()</a></code> </p>
        </td>
        <td><p>Check if an object is a memory format</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="is_torch_qscheme.html">is_torch_qscheme()</a></code> </p>
        </td>
        <td><p>Checks if an object is a QScheme</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="is_undefined_tensor.html">is_undefined_tensor()</a></code> </p>
        </td>
        <td><p>Checks if a tensor is undefined</p></td>
      </tr>
    </tbody><tbody>
      <tr>
        <th colspan="2">
          <h2 id="section-serialization" class="hasAnchor"><a href="#section-serialization" class="anchor"></a>Serialization</h2>
          <p class="section-desc"></p>
        </th>
      </tr>
      
      
    </tbody><tbody>
      
      
      <tr>
        
        <td>
          <p><code><a href="load_state_dict.html">load_state_dict()</a></code> </p>
        </td>
        <td><p>Load a state dict file</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_load.html">torch_load()</a></code> </p>
        </td>
        <td><p>Loads a saved object</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_save.html">torch_save()</a></code> </p>
        </td>
        <td><p>Saves an object to a disk file.</p></td>
      </tr>
    </tbody><tbody>
      <tr>
        <th colspan="2">
          <h2 id="section-mathematical-operations-on-tensors" class="hasAnchor"><a href="#section-mathematical-operations-on-tensors" class="anchor"></a>Mathematical operations on tensors</h2>
          <p class="section-desc"></p>
        </th>
      </tr>
      
      
    </tbody><tbody>
      
      
      <tr>
        
        <td>
          <p><code><a href="threads.html">torch_set_num_threads()</a></code> <code><a href="threads.html">torch_set_num_interop_threads()</a></code> <code><a href="threads.html">torch_get_num_interop_threads()</a></code> <code><a href="threads.html">torch_get_num_threads()</a></code> </p>
        </td>
        <td><p>Number of threads</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_abs.html">torch_abs()</a></code> </p>
        </td>
        <td><p>Abs</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_acos.html">torch_acos()</a></code> </p>
        </td>
        <td><p>Acos</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_adaptive_avg_pool1d.html">torch_adaptive_avg_pool1d()</a></code> </p>
        </td>
        <td><p>Adaptive_avg_pool1d</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_add.html">torch_add()</a></code> </p>
        </td>
        <td><p>Add</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_addbmm.html">torch_addbmm()</a></code> </p>
        </td>
        <td><p>Addbmm</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_addcdiv.html">torch_addcdiv()</a></code> </p>
        </td>
        <td><p>Addcdiv</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_addcmul.html">torch_addcmul()</a></code> </p>
        </td>
        <td><p>Addcmul</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_addmm.html">torch_addmm()</a></code> </p>
        </td>
        <td><p>Addmm</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_addmv.html">torch_addmv()</a></code> </p>
        </td>
        <td><p>Addmv</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_addr.html">torch_addr()</a></code> </p>
        </td>
        <td><p>Addr</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_allclose.html">torch_allclose()</a></code> </p>
        </td>
        <td><p>Allclose</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_angle.html">torch_angle()</a></code> </p>
        </td>
        <td><p>Angle</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_argmax.html">torch_argmax()</a></code> </p>
        </td>
        <td><p>Argmax</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_argmin.html">torch_argmin()</a></code> </p>
        </td>
        <td><p>Argmin</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_argsort.html">torch_argsort()</a></code> </p>
        </td>
        <td><p>Argsort</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_as_strided.html">torch_as_strided()</a></code> </p>
        </td>
        <td><p>As_strided</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_asin.html">torch_asin()</a></code> </p>
        </td>
        <td><p>Asin</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_atan.html">torch_atan()</a></code> </p>
        </td>
        <td><p>Atan</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_atan2.html">torch_atan2()</a></code> </p>
        </td>
        <td><p>Atan2</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_avg_pool1d.html">torch_avg_pool1d()</a></code> </p>
        </td>
        <td><p>Avg_pool1d</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_baddbmm.html">torch_baddbmm()</a></code> </p>
        </td>
        <td><p>Baddbmm</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_bartlett_window.html">torch_bartlett_window()</a></code> </p>
        </td>
        <td><p>Bartlett_window</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_bernoulli.html">torch_bernoulli()</a></code> </p>
        </td>
        <td><p>Bernoulli</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_bincount.html">torch_bincount()</a></code> </p>
        </td>
        <td><p>Bincount</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_bitwise_and.html">torch_bitwise_and()</a></code> </p>
        </td>
        <td><p>Bitwise_and</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_bitwise_not.html">torch_bitwise_not()</a></code> </p>
        </td>
        <td><p>Bitwise_not</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_bitwise_or.html">torch_bitwise_or()</a></code> </p>
        </td>
        <td><p>Bitwise_or</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_bitwise_xor.html">torch_bitwise_xor()</a></code> </p>
        </td>
        <td><p>Bitwise_xor</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_blackman_window.html">torch_blackman_window()</a></code> </p>
        </td>
        <td><p>Blackman_window</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_bmm.html">torch_bmm()</a></code> </p>
        </td>
        <td><p>Bmm</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_broadcast_tensors.html">torch_broadcast_tensors()</a></code> </p>
        </td>
        <td><p>Broadcast_tensors</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_can_cast.html">torch_can_cast()</a></code> </p>
        </td>
        <td><p>Can_cast</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_cartesian_prod.html">torch_cartesian_prod()</a></code> </p>
        </td>
        <td><p>Cartesian_prod</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_cat.html">torch_cat()</a></code> </p>
        </td>
        <td><p>Cat</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_cdist.html">torch_cdist()</a></code> </p>
        </td>
        <td><p>Cdist</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_ceil.html">torch_ceil()</a></code> </p>
        </td>
        <td><p>Ceil</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_celu.html">torch_celu()</a></code> </p>
        </td>
        <td><p>Celu</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_celu_.html">torch_celu_()</a></code> </p>
        </td>
        <td><p>Celu_</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_chain_matmul.html">torch_chain_matmul()</a></code> </p>
        </td>
        <td><p>Chain_matmul</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_cholesky.html">torch_cholesky()</a></code> </p>
        </td>
        <td><p>Cholesky</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_cholesky_inverse.html">torch_cholesky_inverse()</a></code> </p>
        </td>
        <td><p>Cholesky_inverse</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_cholesky_solve.html">torch_cholesky_solve()</a></code> </p>
        </td>
        <td><p>Cholesky_solve</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_chunk.html">torch_chunk()</a></code> </p>
        </td>
        <td><p>Chunk</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_clamp.html">torch_clamp()</a></code> </p>
        </td>
        <td><p>Clamp</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_combinations.html">torch_combinations()</a></code> </p>
        </td>
        <td><p>Combinations</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_conj.html">torch_conj()</a></code> </p>
        </td>
        <td><p>Conj</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_conv1d.html">torch_conv1d()</a></code> </p>
        </td>
        <td><p>Conv1d</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_conv2d.html">torch_conv2d()</a></code> </p>
        </td>
        <td><p>Conv2d</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_conv3d.html">torch_conv3d()</a></code> </p>
        </td>
        <td><p>Conv3d</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_conv_tbc.html">torch_conv_tbc()</a></code> </p>
        </td>
        <td><p>Conv_tbc</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_conv_transpose1d.html">torch_conv_transpose1d()</a></code> </p>
        </td>
        <td><p>Conv_transpose1d</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_conv_transpose2d.html">torch_conv_transpose2d()</a></code> </p>
        </td>
        <td><p>Conv_transpose2d</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_conv_transpose3d.html">torch_conv_transpose3d()</a></code> </p>
        </td>
        <td><p>Conv_transpose3d</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_cos.html">torch_cos()</a></code> </p>
        </td>
        <td><p>Cos</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_cosh.html">torch_cosh()</a></code> </p>
        </td>
        <td><p>Cosh</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_cosine_similarity.html">torch_cosine_similarity()</a></code> </p>
        </td>
        <td><p>Cosine_similarity</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_cross.html">torch_cross()</a></code> </p>
        </td>
        <td><p>Cross</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_cummax.html">torch_cummax()</a></code> </p>
        </td>
        <td><p>Cummax</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_cummin.html">torch_cummin()</a></code> </p>
        </td>
        <td><p>Cummin</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_cumprod.html">torch_cumprod()</a></code> </p>
        </td>
        <td><p>Cumprod</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_cumsum.html">torch_cumsum()</a></code> </p>
        </td>
        <td><p>Cumsum</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_det.html">torch_det()</a></code> </p>
        </td>
        <td><p>Det</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_device.html">torch_device()</a></code> </p>
        </td>
        <td><p>Create a Device object</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_diag.html">torch_diag()</a></code> </p>
        </td>
        <td><p>Diag</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_diag_embed.html">torch_diag_embed()</a></code> </p>
        </td>
        <td><p>Diag_embed</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_diagflat.html">torch_diagflat()</a></code> </p>
        </td>
        <td><p>Diagflat</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_diagonal.html">torch_diagonal()</a></code> </p>
        </td>
        <td><p>Diagonal</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_digamma.html">torch_digamma()</a></code> </p>
        </td>
        <td><p>Digamma</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_dist.html">torch_dist()</a></code> </p>
        </td>
        <td><p>Dist</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_div.html">torch_div()</a></code> </p>
        </td>
        <td><p>Div</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_dot.html">torch_dot()</a></code> </p>
        </td>
        <td><p>Dot</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_eig.html">torch_eig()</a></code> </p>
        </td>
        <td><p>Eig</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_einsum.html">torch_einsum()</a></code> </p>
        </td>
        <td><p>Einsum</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_empty_strided.html">torch_empty_strided()</a></code> </p>
        </td>
        <td><p>Empty_strided</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_eq.html">torch_eq()</a></code> </p>
        </td>
        <td><p>Eq</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_equal.html">torch_equal()</a></code> </p>
        </td>
        <td><p>Equal</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_erf.html">torch_erf()</a></code> </p>
        </td>
        <td><p>Erf</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_erfc.html">torch_erfc()</a></code> </p>
        </td>
        <td><p>Erfc</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_erfinv.html">torch_erfinv()</a></code> </p>
        </td>
        <td><p>Erfinv</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_exp.html">torch_exp()</a></code> </p>
        </td>
        <td><p>Exp</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_expm1.html">torch_expm1()</a></code> </p>
        </td>
        <td><p>Expm1</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_fft.html">torch_fft()</a></code> </p>
        </td>
        <td><p>Fft</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_flatten.html">torch_flatten()</a></code> </p>
        </td>
        <td><p>Flatten</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_flip.html">torch_flip()</a></code> </p>
        </td>
        <td><p>Flip</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_floor.html">torch_floor()</a></code> </p>
        </td>
        <td><p>Floor</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_floor_divide.html">torch_floor_divide()</a></code> </p>
        </td>
        <td><p>Floor_divide</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_fmod.html">torch_fmod()</a></code> </p>
        </td>
        <td><p>Fmod</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_frac.html">torch_frac()</a></code> </p>
        </td>
        <td><p>Frac</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_gather.html">torch_gather()</a></code> </p>
        </td>
        <td><p>Gather</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_ge.html">torch_ge()</a></code> </p>
        </td>
        <td><p>Ge</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_generator.html">torch_generator()</a></code> </p>
        </td>
        <td><p>Create a Generator object</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_geqrf.html">torch_geqrf()</a></code> </p>
        </td>
        <td><p>Geqrf</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_ger.html">torch_ger()</a></code> </p>
        </td>
        <td><p>Ger</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_gt.html">torch_gt()</a></code> </p>
        </td>
        <td><p>Gt</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_hamming_window.html">torch_hamming_window()</a></code> </p>
        </td>
        <td><p>Hamming_window</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_hann_window.html">torch_hann_window()</a></code> </p>
        </td>
        <td><p>Hann_window</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_histc.html">torch_histc()</a></code> </p>
        </td>
        <td><p>Histc</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_ifft.html">torch_ifft()</a></code> </p>
        </td>
        <td><p>Ifft</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_imag.html">torch_imag()</a></code> </p>
        </td>
        <td><p>Imag</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_index_select.html">torch_index_select()</a></code> </p>
        </td>
        <td><p>Index_select</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_inverse.html">torch_inverse()</a></code> </p>
        </td>
        <td><p>Inverse</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_irfft.html">torch_irfft()</a></code> </p>
        </td>
        <td><p>Irfft</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_is_complex.html">torch_is_complex()</a></code> </p>
        </td>
        <td><p>Is_complex</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_is_floating_point.html">torch_is_floating_point()</a></code> </p>
        </td>
        <td><p>Is_floating_point</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_is_installed.html">torch_is_installed()</a></code> </p>
        </td>
        <td><p>Verifies if torch is installed</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_isfinite.html">torch_isfinite()</a></code> </p>
        </td>
        <td><p>Isfinite</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_isinf.html">torch_isinf()</a></code> </p>
        </td>
        <td><p>Isinf</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_isnan.html">torch_isnan()</a></code> </p>
        </td>
        <td><p>Isnan</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_kthvalue.html">torch_kthvalue()</a></code> </p>
        </td>
        <td><p>Kthvalue</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_layout.html">torch_strided()</a></code> <code><a href="torch_layout.html">torch_sparse_coo()</a></code> </p>
        </td>
        <td><p>Creates the corresponding layout</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_le.html">torch_le()</a></code> </p>
        </td>
        <td><p>Le</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_lerp.html">torch_lerp()</a></code> </p>
        </td>
        <td><p>Lerp</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_lgamma.html">torch_lgamma()</a></code> </p>
        </td>
        <td><p>Lgamma</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_log.html">torch_log()</a></code> </p>
        </td>
        <td><p>Log</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_log10.html">torch_log10()</a></code> </p>
        </td>
        <td><p>Log10</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_log1p.html">torch_log1p()</a></code> </p>
        </td>
        <td><p>Log1p</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_log2.html">torch_log2()</a></code> </p>
        </td>
        <td><p>Log2</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_logdet.html">torch_logdet()</a></code> </p>
        </td>
        <td><p>Logdet</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_logical_and.html">torch_logical_and()</a></code> </p>
        </td>
        <td><p>Logical_and</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_logical_not.html">torch_logical_not</a></code> </p>
        </td>
        <td><p>Logical_not</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_logical_or.html">torch_logical_or()</a></code> </p>
        </td>
        <td><p>Logical_or</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_logical_xor.html">torch_logical_xor()</a></code> </p>
        </td>
        <td><p>Logical_xor</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_logsumexp.html">torch_logsumexp()</a></code> </p>
        </td>
        <td><p>Logsumexp</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_lstsq.html">torch_lstsq()</a></code> </p>
        </td>
        <td><p>Lstsq</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_lt.html">torch_lt()</a></code> </p>
        </td>
        <td><p>Lt</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_lu.html">torch_lu()</a></code> </p>
        </td>
        <td><p>LU</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_lu_solve.html">torch_lu_solve()</a></code> </p>
        </td>
        <td><p>Lu_solve</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_manual_seed.html">torch_manual_seed()</a></code> </p>
        </td>
        <td><p>Sets the seed for generating random numbers.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_masked_select.html">torch_masked_select()</a></code> </p>
        </td>
        <td><p>Masked_select</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_matmul.html">torch_matmul()</a></code> </p>
        </td>
        <td><p>Matmul</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_matrix_power.html">torch_matrix_power()</a></code> </p>
        </td>
        <td><p>Matrix_power</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_matrix_rank.html">torch_matrix_rank()</a></code> </p>
        </td>
        <td><p>Matrix_rank</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_max.html">torch_max</a></code> </p>
        </td>
        <td><p>Max</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_mean.html">torch_mean()</a></code> </p>
        </td>
        <td><p>Mean</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_median.html">torch_median()</a></code> </p>
        </td>
        <td><p>Median</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_memory_format.html">torch_contiguous_format()</a></code> <code><a href="torch_memory_format.html">torch_preserve_format()</a></code> <code><a href="torch_memory_format.html">torch_channels_last_format()</a></code> </p>
        </td>
        <td><p>Memory format</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_meshgrid.html">torch_meshgrid()</a></code> </p>
        </td>
        <td><p>Meshgrid</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_min.html">torch_min</a></code> </p>
        </td>
        <td><p>Min</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_mm.html">torch_mm()</a></code> </p>
        </td>
        <td><p>Mm</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_mode.html">torch_mode()</a></code> </p>
        </td>
        <td><p>Mode</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_mul.html">torch_mul()</a></code> </p>
        </td>
        <td><p>Mul</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_multinomial.html">torch_multinomial()</a></code> </p>
        </td>
        <td><p>Multinomial</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_mv.html">torch_mv()</a></code> </p>
        </td>
        <td><p>Mv</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_mvlgamma.html">torch_mvlgamma()</a></code> </p>
        </td>
        <td><p>Mvlgamma</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_narrow.html">torch_narrow()</a></code> </p>
        </td>
        <td><p>Narrow</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_ne.html">torch_ne()</a></code> </p>
        </td>
        <td><p>Ne</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_neg.html">torch_neg()</a></code> </p>
        </td>
        <td><p>Neg</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_nonzero.html">torch_nonzero()</a></code> </p>
        </td>
        <td><p>Nonzero</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_norm.html">torch_norm()</a></code> </p>
        </td>
        <td><p>Norm</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_normal.html">torch_normal()</a></code> </p>
        </td>
        <td><p>Normal</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_orgqr.html">torch_orgqr()</a></code> </p>
        </td>
        <td><p>Orgqr</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_ormqr.html">torch_ormqr()</a></code> </p>
        </td>
        <td><p>Ormqr</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_pdist.html">torch_pdist()</a></code> </p>
        </td>
        <td><p>Pdist</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_pinverse.html">torch_pinverse()</a></code> </p>
        </td>
        <td><p>Pinverse</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_pixel_shuffle.html">torch_pixel_shuffle()</a></code> </p>
        </td>
        <td><p>Pixel_shuffle</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_poisson.html">torch_poisson()</a></code> </p>
        </td>
        <td><p>Poisson</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_polygamma.html">torch_polygamma()</a></code> </p>
        </td>
        <td><p>Polygamma</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_pow.html">torch_pow()</a></code> </p>
        </td>
        <td><p>Pow</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_prod.html">torch_prod()</a></code> </p>
        </td>
        <td><p>Prod</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_promote_types.html">torch_promote_types()</a></code> </p>
        </td>
        <td><p>Promote_types</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_qr.html">torch_qr()</a></code> </p>
        </td>
        <td><p>Qr</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_quantize_per_channel.html">torch_quantize_per_channel()</a></code> </p>
        </td>
        <td><p>Quantize_per_channel</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_quantize_per_tensor.html">torch_quantize_per_tensor()</a></code> </p>
        </td>
        <td><p>Quantize_per_tensor</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_range.html">torch_range()</a></code> </p>
        </td>
        <td><p>Range</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_real.html">torch_real()</a></code> </p>
        </td>
        <td><p>Real</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_reciprocal.html">torch_reciprocal()</a></code> </p>
        </td>
        <td><p>Reciprocal</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_relu.html">torch_relu()</a></code> </p>
        </td>
        <td><p>Relu</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_relu_.html">torch_relu_()</a></code> </p>
        </td>
        <td><p>Relu_</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_remainder.html">torch_remainder()</a></code> </p>
        </td>
        <td><p>Remainder</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_renorm.html">torch_renorm()</a></code> </p>
        </td>
        <td><p>Renorm</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_repeat_interleave.html">torch_repeat_interleave()</a></code> </p>
        </td>
        <td><p>Repeat_interleave</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_reshape.html">torch_reshape()</a></code> </p>
        </td>
        <td><p>Reshape</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_result_type.html">torch_result_type()</a></code> </p>
        </td>
        <td><p>Result_type</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_rfft.html">torch_rfft()</a></code> </p>
        </td>
        <td><p>Rfft</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_roll.html">torch_roll()</a></code> </p>
        </td>
        <td><p>Roll</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_rot90.html">torch_rot90()</a></code> </p>
        </td>
        <td><p>Rot90</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_round.html">torch_round()</a></code> </p>
        </td>
        <td><p>Round</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_rrelu_.html">torch_rrelu_()</a></code> </p>
        </td>
        <td><p>Rrelu_</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_rsqrt.html">torch_rsqrt()</a></code> </p>
        </td>
        <td><p>Rsqrt</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_scalar_tensor.html">torch_scalar_tensor()</a></code> </p>
        </td>
        <td><p>Scalar tensor</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_selu.html">torch_selu()</a></code> </p>
        </td>
        <td><p>Selu</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_selu_.html">torch_selu_()</a></code> </p>
        </td>
        <td><p>Selu_</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_sigmoid.html">torch_sigmoid()</a></code> </p>
        </td>
        <td><p>Sigmoid</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_sign.html">torch_sign()</a></code> </p>
        </td>
        <td><p>Sign</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_sin.html">torch_sin()</a></code> </p>
        </td>
        <td><p>Sin</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_sinh.html">torch_sinh()</a></code> </p>
        </td>
        <td><p>Sinh</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_slogdet.html">torch_slogdet()</a></code> </p>
        </td>
        <td><p>Slogdet</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_solve.html">torch_solve()</a></code> </p>
        </td>
        <td><p>Solve</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_sort.html">torch_sort()</a></code> </p>
        </td>
        <td><p>Sort</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_sparse_coo_tensor.html">torch_sparse_coo_tensor()</a></code> </p>
        </td>
        <td><p>Sparse_coo_tensor</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_split.html">torch_split()</a></code> </p>
        </td>
        <td><p>Split</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_sqrt.html">torch_sqrt()</a></code> </p>
        </td>
        <td><p>Sqrt</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_square.html">torch_square()</a></code> </p>
        </td>
        <td><p>Square</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_squeeze.html">torch_squeeze()</a></code> </p>
        </td>
        <td><p>Squeeze</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_stack.html">torch_stack()</a></code> </p>
        </td>
        <td><p>Stack</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_std.html">torch_std()</a></code> </p>
        </td>
        <td><p>Std</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_std_mean.html">torch_std_mean()</a></code> </p>
        </td>
        <td><p>Std_mean</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_stft.html">torch_stft()</a></code> </p>
        </td>
        <td><p>Stft</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_sum.html">torch_sum()</a></code> </p>
        </td>
        <td><p>Sum</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_svd.html">torch_svd()</a></code> </p>
        </td>
        <td><p>Svd</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_symeig.html">torch_symeig()</a></code> </p>
        </td>
        <td><p>Symeig</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_t.html">torch_t()</a></code> </p>
        </td>
        <td><p>T</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_take.html">torch_take()</a></code> </p>
        </td>
        <td><p>Take</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_tan.html">torch_tan()</a></code> </p>
        </td>
        <td><p>Tan</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_tanh.html">torch_tanh()</a></code> </p>
        </td>
        <td><p>Tanh</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_tensor.html">torch_tensor()</a></code> </p>
        </td>
        <td><p>Converts R objects to a torch tensor</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_tensordot.html">torch_tensordot()</a></code> </p>
        </td>
        <td><p>Tensordot</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_threshold_.html">torch_threshold_()</a></code> </p>
        </td>
        <td><p>Threshold_</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_topk.html">torch_topk()</a></code> </p>
        </td>
        <td><p>Topk</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_trace.html">torch_trace()</a></code> </p>
        </td>
        <td><p>Trace</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_transpose.html">torch_transpose()</a></code> </p>
        </td>
        <td><p>Transpose</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_trapz.html">torch_trapz()</a></code> </p>
        </td>
        <td><p>Trapz</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_triangular_solve.html">torch_triangular_solve()</a></code> </p>
        </td>
        <td><p>Triangular_solve</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_tril.html">torch_tril()</a></code> </p>
        </td>
        <td><p>Tril</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_tril_indices.html">torch_tril_indices()</a></code> </p>
        </td>
        <td><p>Tril_indices</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_triu.html">torch_triu()</a></code> </p>
        </td>
        <td><p>Triu</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_triu_indices.html">torch_triu_indices()</a></code> </p>
        </td>
        <td><p>Triu_indices</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_true_divide.html">torch_true_divide()</a></code> </p>
        </td>
        <td><p>TRUE_divide</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_trunc.html">torch_trunc()</a></code> </p>
        </td>
        <td><p>Trunc</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_unbind.html">torch_unbind()</a></code> </p>
        </td>
        <td><p>Unbind</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_unique_consecutive.html">torch_unique_consecutive()</a></code> </p>
        </td>
        <td><p>Unique_consecutive</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_unsqueeze.html">torch_unsqueeze()</a></code> </p>
        </td>
        <td><p>Unsqueeze</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_var.html">torch_var()</a></code> </p>
        </td>
        <td><p>Var</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_var_mean.html">torch_var_mean()</a></code> </p>
        </td>
        <td><p>Var_mean</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="torch_where.html">torch_where()</a></code> </p>
        </td>
        <td><p>Where</p></td>
      </tr>
    </tbody><tbody>
      <tr>
        <th colspan="2">
          <h2 id="section-neural-network-modules" class="hasAnchor"><a href="#section-neural-network-modules" class="anchor"></a>Neural network modules</h2>
          <p class="section-desc"></p>
        </th>
      </tr>
      
      
    </tbody><tbody>
      
      
      <tr>
        
        <td>
          <p><code><a href="nn_adaptive_avg_pool1d.html">nn_adaptive_avg_pool1d()</a></code> </p>
        </td>
        <td><p>Applies a 1D adaptive average pooling over an input signal composed of several input planes.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_adaptive_avg_pool2d.html">nn_adaptive_avg_pool2d()</a></code> </p>
        </td>
        <td><p>Applies a 2D adaptive average pooling over an input signal composed of several input planes.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_adaptive_avg_pool3d.html">nn_adaptive_avg_pool3d()</a></code> </p>
        </td>
        <td><p>Applies a 3D adaptive average pooling over an input signal composed of several input planes.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_adaptive_log_softmax_with_loss.html">nn_adaptive_log_softmax_with_loss()</a></code> </p>
        </td>
        <td><p>AdaptiveLogSoftmaxWithLoss module</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_adaptive_max_pool1d.html">nn_adaptive_max_pool1d()</a></code> </p>
        </td>
        <td><p>Applies a 1D adaptive max pooling over an input signal composed of several input planes.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_adaptive_max_pool2d.html">nn_adaptive_max_pool2d()</a></code> </p>
        </td>
        <td><p>Applies a 2D adaptive max pooling over an input signal composed of several input planes.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_adaptive_max_pool3d.html">nn_adaptive_max_pool3d()</a></code> </p>
        </td>
        <td><p>Applies a 3D adaptive max pooling over an input signal composed of several input planes.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_avg_pool1d.html">nn_avg_pool1d()</a></code> </p>
        </td>
        <td><p>Applies a 1D average pooling over an input signal composed of several
input planes.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_avg_pool2d.html">nn_avg_pool2d()</a></code> </p>
        </td>
        <td><p>Applies a 2D average pooling over an input signal composed of several input
planes.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_avg_pool3d.html">nn_avg_pool3d()</a></code> </p>
        </td>
        <td><p>Applies a 3D average pooling over an input signal composed of several input
planes.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_batch_norm1d.html">nn_batch_norm1d()</a></code> </p>
        </td>
        <td><p>BatchNorm1D module</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_batch_norm2d.html">nn_batch_norm2d()</a></code> </p>
        </td>
        <td><p>BatchNorm2D</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_bce_loss.html">nn_bce_loss()</a></code> </p>
        </td>
        <td><p>Binary cross entropy loss</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_bce_with_logits_loss.html">nn_bce_with_logits_loss()</a></code> </p>
        </td>
        <td><p>BCE with logits loss</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_bilinear.html">nn_bilinear()</a></code> </p>
        </td>
        <td><p>Bilinear module</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_buffer.html">nn_buffer()</a></code> </p>
        </td>
        <td><p>Creates a nn_buffer</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_celu.html">nn_celu()</a></code> </p>
        </td>
        <td><p>CELU module</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_contrib_sparsemax.html">nn_contrib_sparsemax()</a></code> </p>
        </td>
        <td><p>Sparsemax activation</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_conv1d.html">nn_conv1d()</a></code> </p>
        </td>
        <td><p>Conv1D module</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_conv2d.html">nn_conv2d()</a></code> </p>
        </td>
        <td><p>Conv2D module</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_conv3d.html">nn_conv3d()</a></code> </p>
        </td>
        <td><p>Conv3D module</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_conv_transpose1d.html">nn_conv_transpose1d()</a></code> </p>
        </td>
        <td><p>ConvTranspose1D</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_conv_transpose2d.html">nn_conv_transpose2d()</a></code> </p>
        </td>
        <td><p>ConvTranpose2D module</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_conv_transpose3d.html">nn_conv_transpose3d()</a></code> </p>
        </td>
        <td><p>ConvTranpose3D module</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_cosine_embedding_loss.html">nn_cosine_embedding_loss()</a></code> </p>
        </td>
        <td><p>Cosine embedding loss</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_cross_entropy_loss.html">nn_cross_entropy_loss()</a></code> </p>
        </td>
        <td><p>CrossEntropyLoss module</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_ctc_loss.html">nn_ctc_loss()</a></code> </p>
        </td>
        <td><p>The Connectionist Temporal Classification loss.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_dropout.html">nn_dropout()</a></code> </p>
        </td>
        <td><p>Dropout module</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_dropout2d.html">nn_dropout2d()</a></code> </p>
        </td>
        <td><p>Dropout2D module</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_dropout3d.html">nn_dropout3d()</a></code> </p>
        </td>
        <td><p>Dropout3D module</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_elu.html">nn_elu()</a></code> </p>
        </td>
        <td><p>ELU module</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_embedding.html">nn_embedding()</a></code> </p>
        </td>
        <td><p>Embedding module</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_fractional_max_pool2d.html">nn_fractional_max_pool2d()</a></code> </p>
        </td>
        <td><p>Applies a 2D fractional max pooling over an input signal composed of several input planes.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_fractional_max_pool3d.html">nn_fractional_max_pool3d()</a></code> </p>
        </td>
        <td><p>Applies a 3D fractional max pooling over an input signal composed of several input planes.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_gelu.html">nn_gelu()</a></code> </p>
        </td>
        <td><p>GELU module</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_glu.html">nn_glu()</a></code> </p>
        </td>
        <td><p>GLU module</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_hardshrink.html">nn_hardshrink()</a></code> </p>
        </td>
        <td><p>Hardshwink module</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_hardsigmoid.html">nn_hardsigmoid()</a></code> </p>
        </td>
        <td><p>Hardsigmoid module</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_hardswish.html">nn_hardswish()</a></code> </p>
        </td>
        <td><p>Hardswish module</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_hardtanh.html">nn_hardtanh()</a></code> </p>
        </td>
        <td><p>Hardtanh module</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_hinge_embedding_loss.html">nn_hinge_embedding_loss()</a></code> </p>
        </td>
        <td><p>Hinge embedding loss</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_identity.html">nn_identity()</a></code> </p>
        </td>
        <td><p>Identity module</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_init_calculate_gain.html">nn_init_calculate_gain()</a></code> </p>
        </td>
        <td><p>Calculate gain</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_init_constant_.html">nn_init_constant_()</a></code> </p>
        </td>
        <td><p>Constant initialization</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_init_dirac_.html">nn_init_dirac_()</a></code> </p>
        </td>
        <td><p>Dirac initialization</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_init_eye_.html">nn_init_eye_()</a></code> </p>
        </td>
        <td><p>Eye initialization</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_init_kaiming_normal_.html">nn_init_kaiming_normal_()</a></code> </p>
        </td>
        <td><p>Kaiming normal initialization</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_init_kaiming_uniform_.html">nn_init_kaiming_uniform_()</a></code> </p>
        </td>
        <td><p>Kaiming uniform initialization</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_init_normal_.html">nn_init_normal_()</a></code> </p>
        </td>
        <td><p>Normal initialization</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_init_ones_.html">nn_init_ones_()</a></code> </p>
        </td>
        <td><p>Ones initialization</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_init_orthogonal_.html">nn_init_orthogonal_()</a></code> </p>
        </td>
        <td><p>Orthogonal initialization</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_init_sparse_.html">nn_init_sparse_()</a></code> </p>
        </td>
        <td><p>Sparse initialization</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_init_trunc_normal_.html">nn_init_trunc_normal_()</a></code> </p>
        </td>
        <td><p>Truncated normal initialization</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_init_uniform_.html">nn_init_uniform_()</a></code> </p>
        </td>
        <td><p>Uniform initialization</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_init_xavier_normal_.html">nn_init_xavier_normal_()</a></code> </p>
        </td>
        <td><p>Xavier normal initialization</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_init_xavier_uniform_.html">nn_init_xavier_uniform_()</a></code> </p>
        </td>
        <td><p>Xavier uniform initialization</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_init_zeros_.html">nn_init_zeros_()</a></code> </p>
        </td>
        <td><p>Zeros initialization</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_kl_div_loss.html">nn_kl_div_loss()</a></code> </p>
        </td>
        <td><p>Kullback-Leibler divergence loss</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_l1_loss.html">nn_l1_loss()</a></code> </p>
        </td>
        <td><p>L1 loss</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_leaky_relu.html">nn_leaky_relu()</a></code> </p>
        </td>
        <td><p>LeakyReLU module</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_linear.html">nn_linear()</a></code> </p>
        </td>
        <td><p>Linear module</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_log_sigmoid.html">nn_log_sigmoid()</a></code> </p>
        </td>
        <td><p>LogSigmoid module</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_log_softmax.html">nn_log_softmax()</a></code> </p>
        </td>
        <td><p>LogSoftmax module</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_lp_pool1d.html">nn_lp_pool1d()</a></code> </p>
        </td>
        <td><p>Applies a 1D power-average pooling over an input signal composed of several input
planes.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_lp_pool2d.html">nn_lp_pool2d()</a></code> </p>
        </td>
        <td><p>Applies a 2D power-average pooling over an input signal composed of several input
planes.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_margin_ranking_loss.html">nn_margin_ranking_loss()</a></code> </p>
        </td>
        <td><p>Margin ranking loss</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_max_pool1d.html">nn_max_pool1d()</a></code> </p>
        </td>
        <td><p>MaxPool1D module</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_max_pool2d.html">nn_max_pool2d()</a></code> </p>
        </td>
        <td><p>MaxPool2D module</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_max_pool3d.html">nn_max_pool3d()</a></code> </p>
        </td>
        <td><p>Applies a 3D max pooling over an input signal composed of several input
planes.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_max_unpool1d.html">nn_max_unpool1d()</a></code> </p>
        </td>
        <td><p>Computes a partial inverse of <code>MaxPool1d</code>.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_max_unpool2d.html">nn_max_unpool2d()</a></code> </p>
        </td>
        <td><p>Computes a partial inverse of <code>MaxPool2d</code>.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_max_unpool3d.html">nn_max_unpool3d()</a></code> </p>
        </td>
        <td><p>Computes a partial inverse of <code>MaxPool3d</code>.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_module.html">nn_module()</a></code> </p>
        </td>
        <td><p>Base class for all neural network modules.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_module_list.html">nn_module_list()</a></code> </p>
        </td>
        <td><p>Holds submodules in a list.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_mse_loss.html">nn_mse_loss()</a></code> </p>
        </td>
        <td><p>MSE loss</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_multi_margin_loss.html">nn_multi_margin_loss()</a></code> </p>
        </td>
        <td><p>Multi margin loss</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_multihead_attention.html">nn_multihead_attention()</a></code> </p>
        </td>
        <td><p>MultiHead attention</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_multilabel_margin_loss.html">nn_multilabel_margin_loss()</a></code> </p>
        </td>
        <td><p>Multilabel margin loss</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_multilabel_soft_margin_loss.html">nn_multilabel_soft_margin_loss()</a></code> </p>
        </td>
        <td><p>Multi label soft margin loss</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_nll_loss.html">nn_nll_loss()</a></code> </p>
        </td>
        <td><p>Nll loss</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_pairwise_distance.html">nn_pairwise_distance()</a></code> </p>
        </td>
        <td><p>Pairwise distance</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_parameter.html">nn_parameter()</a></code> </p>
        </td>
        <td><p>Creates an <code>nn_parameter</code></p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_poisson_nll_loss.html">nn_poisson_nll_loss()</a></code> </p>
        </td>
        <td><p>Poisson NLL loss</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_prelu.html">nn_prelu()</a></code> </p>
        </td>
        <td><p>PReLU module</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_relu.html">nn_relu()</a></code> </p>
        </td>
        <td><p>ReLU module</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_relu6.html">nn_relu6()</a></code> </p>
        </td>
        <td><p>ReLu6 module</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_rnn.html">nn_rnn()</a></code> </p>
        </td>
        <td><p>RNN module</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_rrelu.html">nn_rrelu()</a></code> </p>
        </td>
        <td><p>RReLU module</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_selu.html">nn_selu()</a></code> </p>
        </td>
        <td><p>SELU module</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_sequential.html">nn_sequential()</a></code> </p>
        </td>
        <td><p>A sequential container</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_sigmoid.html">nn_sigmoid()</a></code> </p>
        </td>
        <td><p>Sigmoid module</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_smooth_l1_loss.html">nn_smooth_l1_loss()</a></code> </p>
        </td>
        <td><p>Smooth L1 loss</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_soft_margin_loss.html">nn_soft_margin_loss()</a></code> </p>
        </td>
        <td><p>Soft margin loss</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_softmax.html">nn_softmax()</a></code> </p>
        </td>
        <td><p>Softmax module</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_softmax2d.html">nn_softmax2d()</a></code> </p>
        </td>
        <td><p>Softmax2d module</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_softmin.html">nn_softmin()</a></code> </p>
        </td>
        <td><p>Softmin</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_softplus.html">nn_softplus()</a></code> </p>
        </td>
        <td><p>Softplus module</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_softshrink.html">nn_softshrink()</a></code> </p>
        </td>
        <td><p>Softshrink module</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_softsign.html">nn_softsign()</a></code> </p>
        </td>
        <td><p>Softsign module</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_tanh.html">nn_tanh()</a></code> </p>
        </td>
        <td><p>Tanh module</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_tanhshrink.html">nn_tanhshrink()</a></code> </p>
        </td>
        <td><p>Tanhshrink module</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_threshold.html">nn_threshold()</a></code> </p>
        </td>
        <td><p>Threshoold module</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_triplet_margin_loss.html">nn_triplet_margin_loss()</a></code> </p>
        </td>
        <td><p>Triplet margin loss</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_triplet_margin_with_distance_loss.html">nn_triplet_margin_with_distance_loss()</a></code> </p>
        </td>
        <td><p>Triplet margin with distance loss</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_utils_clip_grad_norm_.html">nn_utils_clip_grad_norm_()</a></code> </p>
        </td>
        <td><p>Clips gradient norm of an iterable of parameters.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_utils_clip_grad_value_.html">nn_utils_clip_grad_value_()</a></code> </p>
        </td>
        <td><p>Clips gradient of an iterable of parameters at specified value.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_utils_rnn_pack_padded_sequence.html">nn_utils_rnn_pack_padded_sequence()</a></code> </p>
        </td>
        <td><p>Packs a Tensor containing padded sequences of variable length.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_utils_rnn_pack_sequence.html">nn_utils_rnn_pack_sequence()</a></code> </p>
        </td>
        <td><p>Packs a list of variable length Tensors</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_utils_rnn_pad_packed_sequence.html">nn_utils_rnn_pad_packed_sequence()</a></code> </p>
        </td>
        <td><p>Pads a packed batch of variable length sequences.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nn_utils_rnn_pad_sequence.html">nn_utils_rnn_pad_sequence()</a></code> </p>
        </td>
        <td><p>Pad a list of variable length Tensors with <code>padding_value</code></p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="is_nn_module.html">is_nn_module()</a></code> </p>
        </td>
        <td><p>Checks if the object is an nn_module</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="is_nn_parameter.html">is_nn_parameter()</a></code> </p>
        </td>
        <td><p>Checks if an object is a nn_parameter</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="is_nn_buffer.html">is_nn_buffer()</a></code> </p>
        </td>
        <td><p>Checks if the object is a nn_buffer</p></td>
      </tr>
    </tbody><tbody>
      <tr>
        <th colspan="2">
          <h2 id="section-neural-networks-functional-module" class="hasAnchor"><a href="#section-neural-networks-functional-module" class="anchor"></a>Neural networks functional module</h2>
          <p class="section-desc"></p>
        </th>
      </tr>
      
      
    </tbody><tbody>
      
      
      <tr>
        
        <td>
          <p><code><a href="nnf_adaptive_avg_pool1d.html">nnf_adaptive_avg_pool1d()</a></code> </p>
        </td>
        <td><p>Adaptive_avg_pool1d</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nnf_adaptive_avg_pool2d.html">nnf_adaptive_avg_pool2d()</a></code> </p>
        </td>
        <td><p>Adaptive_avg_pool2d</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nnf_adaptive_avg_pool3d.html">nnf_adaptive_avg_pool3d()</a></code> </p>
        </td>
        <td><p>Adaptive_avg_pool3d</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nnf_adaptive_max_pool1d.html">nnf_adaptive_max_pool1d()</a></code> </p>
        </td>
        <td><p>Adaptive_max_pool1d</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nnf_adaptive_max_pool2d.html">nnf_adaptive_max_pool2d()</a></code> </p>
        </td>
        <td><p>Adaptive_max_pool2d</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nnf_adaptive_max_pool3d.html">nnf_adaptive_max_pool3d()</a></code> </p>
        </td>
        <td><p>Adaptive_max_pool3d</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nnf_affine_grid.html">nnf_affine_grid()</a></code> </p>
        </td>
        <td><p>Affine_grid</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nnf_alpha_dropout.html">nnf_alpha_dropout()</a></code> </p>
        </td>
        <td><p>Alpha_dropout</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nnf_avg_pool1d.html">nnf_avg_pool1d()</a></code> </p>
        </td>
        <td><p>Avg_pool1d</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nnf_avg_pool2d.html">nnf_avg_pool2d()</a></code> </p>
        </td>
        <td><p>Avg_pool2d</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nnf_avg_pool3d.html">nnf_avg_pool3d()</a></code> </p>
        </td>
        <td><p>Avg_pool3d</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nnf_batch_norm.html">nnf_batch_norm()</a></code> </p>
        </td>
        <td><p>Batch_norm</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nnf_bilinear.html">nnf_bilinear()</a></code> </p>
        </td>
        <td><p>Bilinear</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nnf_binary_cross_entropy.html">nnf_binary_cross_entropy()</a></code> </p>
        </td>
        <td><p>Binary_cross_entropy</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nnf_binary_cross_entropy_with_logits.html">nnf_binary_cross_entropy_with_logits()</a></code> </p>
        </td>
        <td><p>Binary_cross_entropy_with_logits</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nnf_celu.html">nnf_celu()</a></code> <code><a href="nnf_celu.html">nnf_celu_()</a></code> </p>
        </td>
        <td><p>Celu</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nnf_contrib_sparsemax.html">nnf_contrib_sparsemax()</a></code> </p>
        </td>
        <td><p>Sparsemax</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nnf_conv1d.html">nnf_conv1d()</a></code> </p>
        </td>
        <td><p>Conv1d</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nnf_conv2d.html">nnf_conv2d()</a></code> </p>
        </td>
        <td><p>Conv2d</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nnf_conv3d.html">nnf_conv3d()</a></code> </p>
        </td>
        <td><p>Conv3d</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nnf_conv_tbc.html">nnf_conv_tbc()</a></code> </p>
        </td>
        <td><p>Conv_tbc</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nnf_conv_transpose1d.html">nnf_conv_transpose1d()</a></code> </p>
        </td>
        <td><p>Conv_transpose1d</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nnf_conv_transpose2d.html">nnf_conv_transpose2d()</a></code> </p>
        </td>
        <td><p>Conv_transpose2d</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nnf_conv_transpose3d.html">nnf_conv_transpose3d()</a></code> </p>
        </td>
        <td><p>Conv_transpose3d</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nnf_cosine_embedding_loss.html">nnf_cosine_embedding_loss()</a></code> </p>
        </td>
        <td><p>Cosine_embedding_loss</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nnf_cosine_similarity.html">nnf_cosine_similarity()</a></code> </p>
        </td>
        <td><p>Cosine_similarity</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nnf_cross_entropy.html">nnf_cross_entropy()</a></code> </p>
        </td>
        <td><p>Cross_entropy</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nnf_ctc_loss.html">nnf_ctc_loss()</a></code> </p>
        </td>
        <td><p>Ctc_loss</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nnf_dropout.html">nnf_dropout()</a></code> </p>
        </td>
        <td><p>Dropout</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nnf_dropout2d.html">nnf_dropout2d()</a></code> </p>
        </td>
        <td><p>Dropout2d</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nnf_dropout3d.html">nnf_dropout3d()</a></code> </p>
        </td>
        <td><p>Dropout3d</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nnf_elu.html">nnf_elu()</a></code> <code><a href="nnf_elu.html">nnf_elu_()</a></code> </p>
        </td>
        <td><p>Elu</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nnf_embedding.html">nnf_embedding()</a></code> </p>
        </td>
        <td><p>Embedding</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nnf_embedding_bag.html">nnf_embedding_bag()</a></code> </p>
        </td>
        <td><p>Embedding_bag</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nnf_fold.html">nnf_fold()</a></code> </p>
        </td>
        <td><p>Fold</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nnf_fractional_max_pool2d.html">nnf_fractional_max_pool2d()</a></code> </p>
        </td>
        <td><p>Fractional_max_pool2d</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nnf_fractional_max_pool3d.html">nnf_fractional_max_pool3d()</a></code> </p>
        </td>
        <td><p>Fractional_max_pool3d</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nnf_gelu.html">nnf_gelu()</a></code> </p>
        </td>
        <td><p>Gelu</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nnf_glu.html">nnf_glu()</a></code> </p>
        </td>
        <td><p>Glu</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nnf_grid_sample.html">nnf_grid_sample()</a></code> </p>
        </td>
        <td><p>Grid_sample</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nnf_group_norm.html">nnf_group_norm()</a></code> </p>
        </td>
        <td><p>Group_norm</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nnf_gumbel_softmax.html">nnf_gumbel_softmax()</a></code> </p>
        </td>
        <td><p>Gumbel_softmax</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nnf_hardshrink.html">nnf_hardshrink()</a></code> </p>
        </td>
        <td><p>Hardshrink</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nnf_hardsigmoid.html">nnf_hardsigmoid()</a></code> </p>
        </td>
        <td><p>Hardsigmoid</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nnf_hardswish.html">nnf_hardswish()</a></code> </p>
        </td>
        <td><p>Hardswish</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nnf_hardtanh.html">nnf_hardtanh()</a></code> <code><a href="nnf_hardtanh.html">nnf_hardtanh_()</a></code> </p>
        </td>
        <td><p>Hardtanh</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nnf_hinge_embedding_loss.html">nnf_hinge_embedding_loss()</a></code> </p>
        </td>
        <td><p>Hinge_embedding_loss</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nnf_instance_norm.html">nnf_instance_norm()</a></code> </p>
        </td>
        <td><p>Instance_norm</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nnf_interpolate.html">nnf_interpolate()</a></code> </p>
        </td>
        <td><p>Interpolate</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nnf_kl_div.html">nnf_kl_div()</a></code> </p>
        </td>
        <td><p>Kl_div</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nnf_l1_loss.html">nnf_l1_loss()</a></code> </p>
        </td>
        <td><p>L1_loss</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nnf_layer_norm.html">nnf_layer_norm()</a></code> </p>
        </td>
        <td><p>Layer_norm</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nnf_leaky_relu.html">nnf_leaky_relu()</a></code> </p>
        </td>
        <td><p>Leaky_relu</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nnf_linear.html">nnf_linear()</a></code> </p>
        </td>
        <td><p>Linear</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nnf_local_response_norm.html">nnf_local_response_norm()</a></code> </p>
        </td>
        <td><p>Local_response_norm</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nnf_log_softmax.html">nnf_log_softmax()</a></code> </p>
        </td>
        <td><p>Log_softmax</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nnf_logsigmoid.html">nnf_logsigmoid()</a></code> </p>
        </td>
        <td><p>Logsigmoid</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nnf_lp_pool1d.html">nnf_lp_pool1d()</a></code> </p>
        </td>
        <td><p>Lp_pool1d</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nnf_lp_pool2d.html">nnf_lp_pool2d()</a></code> </p>
        </td>
        <td><p>Lp_pool2d</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nnf_margin_ranking_loss.html">nnf_margin_ranking_loss()</a></code> </p>
        </td>
        <td><p>Margin_ranking_loss</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nnf_max_pool1d.html">nnf_max_pool1d()</a></code> </p>
        </td>
        <td><p>Max_pool1d</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nnf_max_pool2d.html">nnf_max_pool2d()</a></code> </p>
        </td>
        <td><p>Max_pool2d</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nnf_max_pool3d.html">nnf_max_pool3d()</a></code> </p>
        </td>
        <td><p>Max_pool3d</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nnf_max_unpool1d.html">nnf_max_unpool1d()</a></code> </p>
        </td>
        <td><p>Max_unpool1d</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nnf_max_unpool2d.html">nnf_max_unpool2d()</a></code> </p>
        </td>
        <td><p>Max_unpool2d</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nnf_max_unpool3d.html">nnf_max_unpool3d()</a></code> </p>
        </td>
        <td><p>Max_unpool3d</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nnf_mse_loss.html">nnf_mse_loss()</a></code> </p>
        </td>
        <td><p>Mse_loss</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nnf_multi_head_attention_forward.html">nnf_multi_head_attention_forward()</a></code> </p>
        </td>
        <td><p>Multi head attention forward</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nnf_multi_margin_loss.html">nnf_multi_margin_loss()</a></code> </p>
        </td>
        <td><p>Multi_margin_loss</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nnf_multilabel_margin_loss.html">nnf_multilabel_margin_loss()</a></code> </p>
        </td>
        <td><p>Multilabel_margin_loss</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nnf_multilabel_soft_margin_loss.html">nnf_multilabel_soft_margin_loss()</a></code> </p>
        </td>
        <td><p>Multilabel_soft_margin_loss</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nnf_nll_loss.html">nnf_nll_loss()</a></code> </p>
        </td>
        <td><p>Nll_loss</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nnf_normalize.html">nnf_normalize()</a></code> </p>
        </td>
        <td><p>Normalize</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nnf_one_hot.html">nnf_one_hot()</a></code> </p>
        </td>
        <td><p>One_hot</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nnf_pad.html">nnf_pad()</a></code> </p>
        </td>
        <td><p>Pad</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nnf_pairwise_distance.html">nnf_pairwise_distance()</a></code> </p>
        </td>
        <td><p>Pairwise_distance</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nnf_pdist.html">nnf_pdist()</a></code> </p>
        </td>
        <td><p>Pdist</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nnf_pixel_shuffle.html">nnf_pixel_shuffle()</a></code> </p>
        </td>
        <td><p>Pixel_shuffle</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nnf_poisson_nll_loss.html">nnf_poisson_nll_loss()</a></code> </p>
        </td>
        <td><p>Poisson_nll_loss</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nnf_prelu.html">nnf_prelu()</a></code> </p>
        </td>
        <td><p>Prelu</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nnf_relu.html">nnf_relu()</a></code> <code><a href="nnf_relu.html">nnf_relu_()</a></code> </p>
        </td>
        <td><p>Relu</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nnf_relu6.html">nnf_relu6()</a></code> </p>
        </td>
        <td><p>Relu6</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nnf_rrelu.html">nnf_rrelu()</a></code> <code><a href="nnf_rrelu.html">nnf_rrelu_()</a></code> </p>
        </td>
        <td><p>Rrelu</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nnf_selu.html">nnf_selu()</a></code> <code><a href="nnf_selu.html">nnf_selu_()</a></code> </p>
        </td>
        <td><p>Selu</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nnf_sigmoid.html">nnf_sigmoid()</a></code> </p>
        </td>
        <td><p>Sigmoid</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nnf_smooth_l1_loss.html">nnf_smooth_l1_loss()</a></code> </p>
        </td>
        <td><p>Smooth_l1_loss</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nnf_soft_margin_loss.html">nnf_soft_margin_loss()</a></code> </p>
        </td>
        <td><p>Soft_margin_loss</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nnf_softmax.html">nnf_softmax()</a></code> </p>
        </td>
        <td><p>Softmax</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nnf_softmin.html">nnf_softmin()</a></code> </p>
        </td>
        <td><p>Softmin</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nnf_softplus.html">nnf_softplus()</a></code> </p>
        </td>
        <td><p>Softplus</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nnf_softshrink.html">nnf_softshrink()</a></code> </p>
        </td>
        <td><p>Softshrink</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nnf_softsign.html">nnf_softsign()</a></code> </p>
        </td>
        <td><p>Softsign</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nnf_tanhshrink.html">nnf_tanhshrink()</a></code> </p>
        </td>
        <td><p>Tanhshrink</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nnf_threshold.html">nnf_threshold()</a></code> <code><a href="nnf_threshold.html">nnf_threshold_()</a></code> </p>
        </td>
        <td><p>Threshold</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nnf_triplet_margin_loss.html">nnf_triplet_margin_loss()</a></code> </p>
        </td>
        <td><p>Triplet_margin_loss</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nnf_triplet_margin_with_distance_loss.html">nnf_triplet_margin_with_distance_loss()</a></code> </p>
        </td>
        <td><p>Triplet margin with distance loss</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="nnf_unfold.html">nnf_unfold()</a></code> </p>
        </td>
        <td><p>Unfold</p></td>
      </tr>
    </tbody><tbody>
      <tr>
        <th colspan="2">
          <h2 id="section-optimizers" class="hasAnchor"><a href="#section-optimizers" class="anchor"></a>Optimizers</h2>
          <p class="section-desc"></p>
        </th>
      </tr>
      
      
    </tbody><tbody>
      
      
      <tr>
        
        <td>
          <p><code><a href="optim_adadelta.html">optim_adadelta()</a></code> </p>
        </td>
        <td><p>Adadelta optimizer</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="optim_adagrad.html">optim_adagrad()</a></code> </p>
        </td>
        <td><p>Adagrad optimizer</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="optim_adam.html">optim_adam()</a></code> </p>
        </td>
        <td><p>Implements Adam algorithm.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="optim_asgd.html">optim_asgd()</a></code> </p>
        </td>
        <td><p>Averaged Stochastic Gradient Descent optimizer</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="optim_required.html">optim_required()</a></code> </p>
        </td>
        <td><p>Dummy value indicating a required value.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="optim_rmsprop.html">optim_rmsprop()</a></code> </p>
        </td>
        <td><p>RMSprop optimizer</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="optim_rprop.html">optim_rprop()</a></code> </p>
        </td>
        <td><p>Implements the resilient backpropagation algorithm.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="optim_sgd.html">optim_sgd()</a></code> </p>
        </td>
        <td><p>SGD optimizer</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="is_optimizer.html">is_optimizer()</a></code> </p>
        </td>
        <td><p>Checks if the object is a torch optimizer</p></td>
      </tr>
    </tbody><tbody>
      <tr>
        <th colspan="2">
          <h2 id="section-learning-rate-schedulers" class="hasAnchor"><a href="#section-learning-rate-schedulers" class="anchor"></a>Learning rate schedulers</h2>
          <p class="section-desc"></p>
        </th>
      </tr>
      
      
    </tbody><tbody>
      
      
      <tr>
        
        <td>
          <p><code><a href="lr_lambda.html">lr_lambda()</a></code> </p>
        </td>
        <td><p>Sets the learning rate of each parameter group to the initial lr
times a given function. When last_epoch=-1, sets initial lr as lr.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="lr_multiplicative.html">lr_multiplicative()</a></code> </p>
        </td>
        <td><p>Multiply the learning rate of each parameter group by the factor given
in the specified function. When last_epoch=-1, sets initial lr as lr.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="lr_one_cycle.html">lr_one_cycle()</a></code> </p>
        </td>
        <td><p>Once cycle learning rate</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="lr_scheduler.html">lr_scheduler()</a></code> </p>
        </td>
        <td><p>Creates learning rate schedulers</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="lr_step.html">lr_step()</a></code> </p>
        </td>
        <td><p>Step learning rate decay</p></td>
      </tr>
    </tbody><tbody>
      <tr>
        <th colspan="2">
          <h2 id="section-datasets" class="hasAnchor"><a href="#section-datasets" class="anchor"></a>Datasets</h2>
          <p class="section-desc"></p>
        </th>
      </tr>
      
      
    </tbody><tbody>
      
      
      <tr>
        
        <td>
          <p><code><a href="dataset.html">dataset()</a></code> </p>
        </td>
        <td><p>An abstract class representing a <code>Dataset</code>.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="dataloader.html">dataloader()</a></code> </p>
        </td>
        <td><p>Data loader. Combines a dataset and a sampler, and provides
single- or multi-process iterators over the dataset.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="dataloader_make_iter.html">dataloader_make_iter()</a></code> </p>
        </td>
        <td><p>Creates an iterator from a DataLoader</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="dataloader_next.html">dataloader_next()</a></code> </p>
        </td>
        <td><p>Get the next element of a dataloader iterator</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="enumerate.html">enumerate()</a></code> </p>
        </td>
        <td><p>Enumerate an iterator</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="enumerate.dataloader.html">enumerate(<i>&lt;dataloader&gt;</i>)</a></code> </p>
        </td>
        <td><p>Enumerate an iterator</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="tensor_dataset.html">tensor_dataset()</a></code> </p>
        </td>
        <td><p>Dataset wrapping tensors.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="is_dataloader.html">is_dataloader()</a></code> </p>
        </td>
        <td><p>Checks if the object is a dataloader</p></td>
      </tr>
    </tbody><tbody>
      <tr>
        <th colspan="2">
          <h2 id="section-autograd" class="hasAnchor"><a href="#section-autograd" class="anchor"></a>Autograd</h2>
          <p class="section-desc"></p>
        </th>
      </tr>
      
      
    </tbody><tbody>
      
      
      <tr>
        
        <td>
          <p><code><a href="autograd_backward.html">autograd_backward()</a></code> </p>
        </td>
        <td><p>Computes the sum of gradients of given tensors w.r.t. graph leaves.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="autograd_function.html">autograd_function()</a></code> </p>
        </td>
        <td><p>Records operation history and defines formulas for differentiating ops.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="autograd_grad.html">autograd_grad()</a></code> </p>
        </td>
        <td><p>Computes and returns the sum of gradients of outputs w.r.t. the inputs.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="autograd_set_grad_mode.html">autograd_set_grad_mode()</a></code> </p>
        </td>
        <td><p>Set grad mode</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="with_no_grad.html">with_no_grad()</a></code> </p>
        </td>
        <td><p>Temporarily modify gradient recording.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="with_enable_grad.html">with_enable_grad()</a></code> </p>
        </td>
        <td><p>Enable grad</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="AutogradContext.html">AutogradContext</a></code> </p>
        </td>
        <td><p>Class representing the context.</p></td>
      </tr>
    </tbody><tbody>
      <tr>
        <th colspan="2">
          <h2 id="section-cuda-utilities" class="hasAnchor"><a href="#section-cuda-utilities" class="anchor"></a>Cuda utilities</h2>
          <p class="section-desc"></p>
        </th>
      </tr>
      
      
    </tbody><tbody>
      
      
      <tr>
        
        <td>
          <p><code><a href="cuda_current_device.html">cuda_current_device()</a></code> </p>
        </td>
        <td><p>Returns the index of a currently selected device.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="cuda_device_count.html">cuda_device_count()</a></code> </p>
        </td>
        <td><p>Returns the number of GPUs available.</p></td>
      </tr><tr>
        
        <td>
          <p><code><a href="cuda_is_available.html">cuda_is_available()</a></code> </p>
        </td>
        <td><p>Returns a bool indicating if CUDA is currently available.</p></td>
      </tr>
    </tbody><tbody>
      <tr>
        <th colspan="2">
          <h2 id="section-installation" class="hasAnchor"><a href="#section-installation" class="anchor"></a>Installation</h2>
          <p class="section-desc"></p>
        </th>
      </tr>
      
      
    </tbody><tbody>
      
      
      <tr>
        
        <td>
          <p><code><a href="install_torch.html">install_torch()</a></code> </p>
        </td>
        <td><p>Install Torch</p></td>
      </tr>
    </tbody>
    </table>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">
    <nav id="toc" data-toggle="toc" class="sticky-top">
      <h2 data-toc-skip>Contents</h2>
    </nav>
  </div>
</div>


      <footer>
      <div class="copyright">
  <p>Developed by Daniel Falbel, Javier Luraschi.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.6.1.</p>
</div>

      </footer>
   </div>

  


  </body>
</html>


